{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Download data for training\n",
    "currency_data = yf.download('USDINR=X', start='2020-01-01', end='2023-01-01')\n",
    "currency_data = currency_data[['Close']].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for optimization (Mean Squared Error)\n",
    "def objective_function(hyperparameters, data):\n",
    "    lstm_units = int(hyperparameters[0])  # Number of LSTM units\n",
    "    learning_rate = hyperparameters[1]    # Learning rate\n",
    "    batch_size = int(hyperparameters[2])  # Batch size\n",
    "\n",
    "    # Data preprocessing\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data.values)\n",
    "\n",
    "    # Prepare the data for LSTM\n",
    "    def create_dataset(data, time_step=60):\n",
    "        X, y = [], []\n",
    "        for i in range(time_step, len(data)):\n",
    "            X.append(data[i-time_step:i, 0])  # past 'time_step' days\n",
    "            y.append(data[i, 0])  # next day price\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    X, y = create_dataset(scaled_data)\n",
    "\n",
    "    # Reshape data into 3D input for LSTM\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "    # Build and compile the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(X.shape[1], 1)))  # Proper input layer\n",
    "    model.add(LSTM(units=lstm_units, return_sequences=True))\n",
    "    model.add(LSTM(units=lstm_units, return_sequences=False))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X, y, epochs=10, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = model.evaluate(X, y, verbose=0)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the HOA algorithm with constraints on hyperparameters\n",
    "def hoa_algorithm(data, population_size=10, max_iter=100, search_space=(-1, 1)):\n",
    "    # Initialize population with constrained ranges\n",
    "    population = np.random.uniform(search_space[0], search_space[1], (population_size, 3))  # Hyperparameters: LSTM units, learning rate, batch size\n",
    "    \n",
    "    # Enforce constraints\n",
    "    population[:, 0] = np.clip(population[:, 0], 10, 200)  # LSTM units between 10 and 200\n",
    "    population[:, 2] = np.clip(population[:, 2], 16, 64)   # Batch size between 16 and 64\n",
    "    population[:, 1] = np.clip(population[:, 1], 0.0001, 0.01)  # Learning rate between 0.0001 and 0.01\n",
    "    \n",
    "    best_solution = population[0]\n",
    "    best_score = objective_function(best_solution, data)\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        for i in range(population_size):\n",
    "            # Small perturbations for hyperparameters\n",
    "            candidate = population[i] + np.random.uniform(-0.1, 0.1, 3)\n",
    "            \n",
    "            # Apply constraints to candidate solution\n",
    "            candidate[0] = np.clip(candidate[0], 10, 200)  # LSTM units\n",
    "            candidate[2] = np.clip(candidate[2], 16, 64)   # Batch size\n",
    "            candidate[1] = np.clip(candidate[1], 0.0001, 0.01)  # Learning rate\n",
    "            \n",
    "            candidate_score = objective_function(candidate, data)\n",
    "            \n",
    "            if candidate_score < best_score:\n",
    "                best_solution = candidate\n",
    "                best_score = candidate_score\n",
    "        \n",
    "        print(f\"Iteration {iteration+1}/{max_iter} - Best Score: {best_score}\")\n",
    "    \n",
    "    return best_solution, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/100 - Best Score: 0.0008870054152794182\n",
      "Iteration 2/100 - Best Score: 0.0008870054152794182\n",
      "Iteration 3/100 - Best Score: 0.0008870054152794182\n",
      "Iteration 4/100 - Best Score: 0.0008870054152794182\n",
      "Iteration 5/100 - Best Score: 0.0008384888642467558\n",
      "Iteration 6/100 - Best Score: 0.0008384888642467558\n",
      "Iteration 7/100 - Best Score: 0.0008384888642467558\n",
      "Iteration 8/100 - Best Score: 0.0008384888642467558\n",
      "Iteration 9/100 - Best Score: 0.0008384888642467558\n",
      "Iteration 10/100 - Best Score: 0.0008384888642467558\n",
      "Iteration 11/100 - Best Score: 0.0008384888642467558\n",
      "Iteration 12/100 - Best Score: 0.000763254938647151\n",
      "Iteration 13/100 - Best Score: 0.000763254938647151\n",
      "Iteration 14/100 - Best Score: 0.000763254938647151\n",
      "Iteration 15/100 - Best Score: 0.000763254938647151\n",
      "Iteration 16/100 - Best Score: 0.000763254938647151\n",
      "Iteration 17/100 - Best Score: 0.000763254938647151\n",
      "Iteration 18/100 - Best Score: 0.000763254938647151\n",
      "Iteration 19/100 - Best Score: 0.000763254938647151\n",
      "Iteration 20/100 - Best Score: 0.000763254938647151\n",
      "Iteration 21/100 - Best Score: 0.000763254938647151\n",
      "Iteration 22/100 - Best Score: 0.000763254938647151\n",
      "Iteration 23/100 - Best Score: 0.000763254938647151\n",
      "Iteration 24/100 - Best Score: 0.000763254938647151\n",
      "Iteration 25/100 - Best Score: 0.000763254938647151\n",
      "Iteration 26/100 - Best Score: 0.000763254938647151\n",
      "Iteration 27/100 - Best Score: 0.000763254938647151\n",
      "Iteration 28/100 - Best Score: 0.000763254938647151\n",
      "Iteration 29/100 - Best Score: 0.000763254938647151\n",
      "Iteration 30/100 - Best Score: 0.000763254938647151\n",
      "Iteration 31/100 - Best Score: 0.000763254938647151\n",
      "Iteration 32/100 - Best Score: 0.000763254938647151\n",
      "Iteration 33/100 - Best Score: 0.000763254938647151\n",
      "Iteration 34/100 - Best Score: 0.000763254938647151\n",
      "Iteration 35/100 - Best Score: 0.000763254938647151\n",
      "Iteration 36/100 - Best Score: 0.000763254938647151\n",
      "Iteration 37/100 - Best Score: 0.000763254938647151\n",
      "Iteration 38/100 - Best Score: 0.000763254938647151\n",
      "Iteration 39/100 - Best Score: 0.000763254938647151\n",
      "Iteration 40/100 - Best Score: 0.000763254938647151\n",
      "Iteration 41/100 - Best Score: 0.000763254938647151\n",
      "Iteration 42/100 - Best Score: 0.000763254938647151\n",
      "Iteration 43/100 - Best Score: 0.000763254938647151\n",
      "Iteration 44/100 - Best Score: 0.000763254938647151\n",
      "Iteration 45/100 - Best Score: 0.000763254938647151\n",
      "Iteration 46/100 - Best Score: 0.000763254938647151\n",
      "Iteration 47/100 - Best Score: 0.000763254938647151\n",
      "Iteration 48/100 - Best Score: 0.000763254938647151\n",
      "Iteration 49/100 - Best Score: 0.000763254938647151\n",
      "Iteration 50/100 - Best Score: 0.000763254938647151\n",
      "Iteration 51/100 - Best Score: 0.000763254938647151\n",
      "Iteration 52/100 - Best Score: 0.000763254938647151\n",
      "Iteration 53/100 - Best Score: 0.000763254938647151\n",
      "Iteration 54/100 - Best Score: 0.000763254938647151\n",
      "Iteration 55/100 - Best Score: 0.000763254938647151\n",
      "Iteration 56/100 - Best Score: 0.000763254938647151\n",
      "Iteration 57/100 - Best Score: 0.000763254938647151\n",
      "Iteration 58/100 - Best Score: 0.000763254938647151\n",
      "Iteration 59/100 - Best Score: 0.000763254938647151\n",
      "Iteration 60/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 61/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 62/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 63/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 64/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 65/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 66/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 67/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 68/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 69/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 70/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 71/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 72/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 73/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 74/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 75/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 76/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 77/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 78/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 79/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 80/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 81/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 82/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 83/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 84/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 85/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 86/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 87/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 88/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 89/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 90/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 91/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 92/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 93/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 94/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 95/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 96/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 97/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 98/100 - Best Score: 0.0007545409025624394\n",
      "Iteration 99/100 - Best Score: 0.0007277006516233087\n",
      "Iteration 100/100 - Best Score: 0.0007277006516233087\n",
      "Best Hyperparameters: [1.00452103e+01 1.00000000e-02 1.60000000e+01], with MSE: 0.0007277006516233087\n"
     ]
    }
   ],
   "source": [
    "# Run HOA to optimize hyperparameters\n",
    "best_hyperparameters, best_mse = hoa_algorithm(currency_data)\n",
    "print(f\"Best Hyperparameters: {best_hyperparameters}, with MSE: {best_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model using the optimized hyperparameters\n",
    "lstm_units = int(best_hyperparameters[0])\n",
    "learning_rate = best_hyperparameters[1]\n",
    "batch_size = int(best_hyperparameters[2])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(currency_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, time_step=60):\n",
    "    X, y = [], []\n",
    "    for i in range(time_step, len(data)):\n",
    "        X.append(data[i-time_step:i, 0])  # past 'time_step' days\n",
    "        y.append(data[i, 0])  # next day price\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_dataset(scaled_data)\n",
    "\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the optimized LSTM model\n",
    "model = Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(X.shape[1], 1)))  # Corrected input layer\n",
    "model.add(LSTM(units=lstm_units, return_sequences=True))\n",
    "model.add(LSTM(units=lstm_units, return_sequences=False))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0349\n",
      "Epoch 2/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0020\n",
      "Epoch 3/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0019\n",
      "Epoch 4/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0015\n",
      "Epoch 5/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0017\n",
      "Epoch 6/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0022\n",
      "Epoch 7/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013\n",
      "Epoch 8/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0013\n",
      "Epoch 9/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012\n",
      "Epoch 10/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14b57d2af40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, y, epochs=10, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'optimized_lstm_currency_model.keras'\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save(\"optimized_lstm_currency_model.keras\")\n",
    "print(\"Model saved as 'optimized_lstm_currency_model.keras'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
